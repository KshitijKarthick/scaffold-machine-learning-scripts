{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import cPickle\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the filename\n",
    "FILENAME = 'dummy.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants Declaration\n",
    "DATASET_DIR = './data/'\n",
    "RESULT_DIR = './result/'\n",
    "RANDOM_SEED = 42\n",
    "EXTENSION_MAPPING = {\n",
    "    'read': {\n",
    "        'csv': 'read_csv',\n",
    "        'json': 'read_json',\n",
    "        'xlsx': 'read_excel'   \n",
    "    },\n",
    "    'save': {\n",
    "        'csv': 'to_csv',\n",
    "        'json': 'to_json',\n",
    "        'xlsx': 'to_excel'      \n",
    "    }\n",
    "}\n",
    "np.random.seed(seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset Loader\n",
    "DATASET_FILE = os.path.join(DATASET_DIR, FILENAME)\n",
    "file_path, file_extension = os.path.splitext(DATASET_FILE)\n",
    "file_name = file_path.split(os.path.sep)[-1]\n",
    "file_extension = file_extension.strip('.')\n",
    "dataset_extracter = EXTENSION_MAPPING['read'].get(file_extension)\n",
    "if dataset_extracter is None:\n",
    "    raise ValueError('Dataset type not supported')\n",
    "df = getattr(pd, dataset_extracter)(DATASET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>john</td>\n",
       "      <td>23</td>\n",
       "      <td>2004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>tom</td>\n",
       "      <td>45</td>\n",
       "      <td>2006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>sam</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>harry</td>\n",
       "      <td>2012</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>jim</td>\n",
       "      <td>23</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name   age    year\n",
       "0   1   john    23  2004.0\n",
       "1   2    tom    45  2006.0\n",
       "2   3    sam    64     NaN\n",
       "3   4  harry  2012     NaN\n",
       "4   5    jim    23  2014.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = list(set(['age']))\n",
    "dependent_columns = list(set(df.columns) - set(target_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[dependent_columns], df[target_columns],\n",
    "    test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing values\n",
    "* Replace with Mean Values\n",
    "* Replace with Median Values\n",
    "* Replace with Most Common Values\n",
    "* Replace with Specific Value\n",
    "* Drop records with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing with Sklearn, Fill with mean values for the required columns.\n",
    "\n",
    "required_columns = []\n",
    "imputer = Imputer(missing_values=np.nan, strategy=\"mean\", axis=0)\n",
    "if len(required_columns) > 0:\n",
    "    X_train[required_columns] = pd.DataFrame(imputer.fit_transform(X_train[required_columns]))\n",
    "    X_test[required_columns] = pd.DataFrame(imputer.transform(X_test[required_columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing with Sklearn, Fill with median values for the required columns.\n",
    "\n",
    "required_columns = []\n",
    "imputer = Imputer(missing_values=np.nan, strategy=\"median\", axis=0)\n",
    "if len(required_columns) > 0:\n",
    "    X_train[required_columns] = pd.DataFrame(imputer.fit_transform(X_train[required_columns]))\n",
    "    X_test[required_columns] = pd.DataFrame(imputer.transform(X_test[required_columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing with Sklearn, Fill with most frequent values for the required columns.\n",
    "\n",
    "required_columns = []\n",
    "imputer = Imputer(missing_values=np.nan, strategy=\"median\", axis=0)\n",
    "if len(required_columns) > 0:\n",
    "    X_train[required_columns] = pd.DataFrame(imputer.fit_transform(X_train[required_columns]))\n",
    "    X_test[required_columns] = pd.DataFrame(imputer.transform(X_test[required_columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing with Pandas, Fill with a specific value.\n",
    "\n",
    "value = 0\n",
    "required_columns = []\n",
    "if len(required_columns) > 0:\n",
    "    X_train[required_columns] = X_train[required_columns].fillna(value)\n",
    "    X_test[required_columns] = X_test[required_columns].fillna(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing with Pandas, Drop missing values\n",
    "\n",
    "required_columns = []\n",
    "if len(required_columns) > 0:\n",
    "    X_train.dropna(subset=required_columns, inplace=True, how='any')\n",
    "    X_test.dropna(subset=required_columns, inplace=True, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Features\n",
    "* Target Features\n",
    "    * Multiclass Classification\n",
    "        * Binary\n",
    "        * Non Binary\n",
    "    * Multilabel Classification\n",
    "* Dependent Features\n",
    "    * Encode Classes to Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non Binary Multiclass Classification / Encode Classes to Labels\n",
    "\n",
    "required_columns = []\n",
    "label_encoders = {}\n",
    "for column in required_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    if column in X_train.columns:\n",
    "        X_train[column] = label_encoders[column].fit_transform(X_train[column])\n",
    "        X_test[column] = label_encoders[column].transform(X_test[column])\n",
    "    elif column in y_train.columns:\n",
    "        y_train[column] = label_encoders[column].fit_transform(y_train[column])\n",
    "        y_test[column] = label_encoders[column].transform(y_test[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass Binary Classification\n",
    "\n",
    "# Only a single column is expected\n",
    "required_columns = ['age']\n",
    "label_binarizer = None\n",
    "if len(required_columns) > 0:\n",
    "    column = required_columns[0]\n",
    "    if column in X_train.columns:\n",
    "        label_binarizer = LabelBinarizer()\n",
    "        X_train[column] = label_binarizer.fit_transform(X_train[column])\n",
    "        X_test[column] = label_binarizer.transform(X_test[column])\n",
    "    elif column in y_train.columns:\n",
    "        label_binarizer = LabelBinarizer()\n",
    "        y_train[column] = label_binarizer.fit_transform(y_train[column])\n",
    "        y_test[column] = label_binarizer.transform(y_test[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilabel Binary Classification\n",
    "\n",
    "# Only a single column is expected\n",
    "required_columns = []\n",
    "\n",
    "multi_label_binarizer = None\n",
    "if len(required_columns) > 0:\n",
    "    column = required_columns[0]\n",
    "    if column in y_train.columns:\n",
    "        multi_label_binarizer = MultiLabelBinarizer()\n",
    "        y_train[column] = multi_label_binarizer.fit_transform(y_train[column])\n",
    "        y_test[column] = multi_label_binarizer.transform(y_test[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage of results.\n",
    "result_time = datetime.utcnow().strftime('%s')\n",
    "save_dataset_fn = EXTENSION_MAPPING['save'].get(file_extension.strip('.'))\n",
    "getattr(pd.concat([X_train, y_train], axis=1), save_dataset_fn)(os.path.join(RESULT_DIR, '{}.train.result.{}.{}'.format(file_name, result_time, file_extension)))\n",
    "getattr(pd.concat([X_test, y_test], axis=1), save_dataset_fn)(os.path.join(RESULT_DIR, '{}.test.result.{}.{}'.format(file_name, result_time, file_extension)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(label_encoders) > 0:\n",
    "    with open(os.path.join(RESULT_DIR, '{}.result.label_encoders.{}.{}'.format(file_name, result_time, file_extension)), 'wb') as encoder_fp:\n",
    "        cPickle.dump(label_encoders, encoder_fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
